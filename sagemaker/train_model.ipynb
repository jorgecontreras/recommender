{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import Session\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AWS resources\n",
    "s3_bucket = \"recommender-system-demo\"\n",
    "s3_prefix = \"training-data\"\n",
    "sagemaker_role = \"arn:aws:iam::YOUR_ACCOUNT_ID:role/service-role/AmazonSageMaker-ExecutionRole\"\n",
    "\n",
    "# Initialize boto3 clients\n",
    "s3_client = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess data\n",
    "def load_and_preprocess_data():\n",
    "    # Load dataset\n",
    "    movies_file = f\"s3://{s3_bucket}/processed/movies.csv\"\n",
    "    ratings_file = f\"s3://{s3_bucket}/processed/ratings.csv\"\n",
    "\n",
    "    movies_df = pd.read_csv(movies_file)\n",
    "    ratings_df = pd.read_csv(ratings_file)\n",
    "\n",
    "    # Merge datasets\n",
    "    data = pd.merge(ratings_df, movies_df, on=\"movieId\")\n",
    "    \n",
    "    # Prepare for training\n",
    "    data = data[[\"userId\", \"movieId\", \"rating\"]]\n",
    "\n",
    "    # Encode user_id and movie_id as integers\n",
    "    data[\"userId\"] = data[\"userId\"].astype(\"category\").cat.codes\n",
    "    data[\"movieId\"] = data[\"movieId\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Save preprocessed data to S3\n",
    "    train.to_csv(\"train.csv\", index=False)\n",
    "    test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "    s3_client.upload_file(\"train.csv\", s3_bucket, f\"{s3_prefix}/train/train.csv\")\n",
    "    s3_client.upload_file(\"test.csv\", s3_bucket, f\"{s3_prefix}/test/test.csv\")\n",
    "\n",
    "    print(\"Data preprocessing completed and uploaded to S3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Train model\n",
    "def train_model():\n",
    "    session = Session()\n",
    "\n",
    "    container = get_image_uri(boto3.Session().region_name, \"factorization-machines\")\n",
    "    \n",
    "    # Define estimator\n",
    "    estimator = Estimator(\n",
    "        container,\n",
    "        role=sagemaker_role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        output_path=f\"s3://{s3_bucket}/output\"\n",
    "    )\n",
    "\n",
    "    # Specify input data\n",
    "    train_input = f\"s3://{s3_bucket}/{s3_prefix}/train\"\n",
    "    test_input = f\"s3://{s3_bucket}/{s3_prefix}/test\"\n",
    "\n",
    "    estimator.fit({\n",
    "        \"train\": train_input,\n",
    "        \"test\": test_input\n",
    "    })\n",
    "\n",
    "    print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Deploy model\n",
    "def deploy_model():\n",
    "    # Deploy the model\n",
    "    predictor = estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        endpoint_name=\"recommender-endpoint\"\n",
    "    )\n",
    "\n",
    "    print(f\"Model deployed at endpoint: recommender-endpoint\")\n",
    "    return predictor\n",
    "\n",
    "# Execute the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    load_and_preprocess_data()\n",
    "    train_model()\n",
    "    deploy_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
